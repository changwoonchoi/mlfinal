{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D0zuYQzwiO8Z"
   },
   "source": [
    "# M2608.001300 Machine Learning<br> Assignment #5 Final Projects (Pytorch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ri0oOICuC64e"
   },
   "source": [
    "Copyright (C) Data Science & AI Laboratory, Seoul National University. This material is for educational uses only. Some contents are based on the material provided by other paper/book authors and may be copyrighted by them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CJfG1l3RC_c3"
   },
   "source": [
    "**For understanding of this work, please carefully look at given PPT file.**\n",
    "\n",
    "Note: certain details are missing or ambiguous on purpose, in order to test your knowledge on the related materials. However, if you really feel that something essential is missing and cannot proceed to the next step, then contact the teaching staff with clear description of your problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "M9yv4oGGDbmJ",
    "outputId": "76b24c10-0f36-407e-9bb7-2c9ce3b5edff"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "acvGcUAaEkxe"
   },
   "source": [
    "Load datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "UcPk4u8qGZHB",
    "outputId": "5b4bfcbc-c731-4704-ae17-649e9f6d16ac"
   },
   "outputs": [],
   "source": [
    "NUMBER = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "ALPHABET = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "NONE = ['NONE'] # label for empty space\n",
    "ALL_CHAR_SET = NUMBER + ALPHABET + NONE\n",
    "ALL_CHAR_SET_LEN = len(ALL_CHAR_SET)\n",
    "MAX_CAPTCHA = 7\n",
    "\n",
    "#print(ALL_CHAR_SET_LEN)\n",
    "#print(ALL_CHAR_SET.index('NONE'))\n",
    "#print(ALL_CHAR_SET)\n",
    "\n",
    "def encode(a):\n",
    "    onehot = [0]*ALL_CHAR_SET_LEN\n",
    "    idx = ALL_CHAR_SET.index(a)\n",
    "    onehot[idx] += 1\n",
    "    return onehot\n",
    "\n",
    "# modified dataset class\n",
    "class Mydataset(Dataset):\n",
    "    def __init__(self, img_path, label_path, is_train=True, transform=None):\n",
    "        self.path = img_path\n",
    "        self.label_path = label_path\n",
    "        if is_train: \n",
    "            self.img = os.listdir(self.path)[:3]\n",
    "            #self.labels = open(self.label_path, 'r').read().split('\\n')[:-1][:10000]\n",
    "            self.labels = open(self.label_path, 'r').read().split('\\n')[:-1][:3]\n",
    "        else: \n",
    "            self.img = os.listdir(self.path)[:1000]\n",
    "            self.labels = open(self.label_path, 'r').read().split('\\n')[:-1][:1000]\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.max_length = MAX_CAPTCHA\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img[idx]\n",
    "        img = Image.open(f'{self.path}/{self.img[idx]}')\n",
    "        # convert to gray mode\n",
    "        img = img.convert('L')\n",
    "        label = self.labels[idx]\n",
    "        #print(label)\n",
    "        label_oh = []\n",
    "        \n",
    "        # one-hot for each character\n",
    "                \n",
    "        for i in range(self.max_length):\n",
    "            if i < len(label):\n",
    "                label_oh += encode(label[i])\n",
    "            else:\n",
    "                #label_oh += [0]*ALL_CHAR_SET_LEN\n",
    "                label_oh += encode('NONE')\n",
    "            \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        #print(img.shape)\n",
    "        #print(type(label_oh))\n",
    "        #print(label)\n",
    "        return img, np.array(label_oh), label\n",
    "    def __len__(self):\n",
    "        return len(self.img)\n",
    "\n",
    "\n",
    "    \n",
    "#data size : 160*60\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize([160, 60]),\n",
    "    transforms.ToTensor()\n",
    "\n",
    "#TODO\n",
    "    #ColorJitter\n",
    "    #RandomAffine\n",
    "    #randomapply\n",
    "    #...\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 160, 60])\n",
      "torch.Size([3, 259])\n",
      "('yib8', '2vb', 'ho4')\n"
     ]
    }
   ],
   "source": [
    "for step, i in enumerate(train_dl):\n",
    "        img, label_oh, label = i\n",
    "        print(img.shape)\n",
    "        print(label_oh.shape)\n",
    "        #print(label_oh)\n",
    "        print(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "EFtlQyubGJZb",
    "outputId": "4697c0a5-d24a-4e05-f226-14021b625f5e"
   },
   "outputs": [],
   "source": [
    "\"\"\"Loading DATA\"\"\"\n",
    "# Change to your own data folder path!\n",
    "gPath = './'\n",
    "\n",
    "train_ds = Mydataset(gPath+'Data/train/', gPath+'Data/train.txt',transform=transform)\n",
    "test_ds = Mydataset(gPath+'Data/test/', gPath+'Data/test.txt',False, transform)\n",
    "train_dl = DataLoader(train_ds, batch_size=128, num_workers=4)\n",
    "test_dl = DataLoader(test_ds, batch_size=1, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ka5SgX6VIWcG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "\"\"\"To CUDA for local run\"\"\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.is_available())\n",
    "#GPUID = '4' # define GPUID\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(GPUID)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tJaHW3wSENjY"
   },
   "source": [
    "Problem 1: Design LSTM model for captcha image recognition. (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "rHEe3XmBFQHq",
    "outputId": "5b4bfcbc-c731-4704-ae17-649e9f6d16ac"
   },
   "outputs": [],
   "source": [
    "#TODO 1 : stack lstm layers\n",
    "#TODO 2 : bidirectional RNN (since this captcha data has no sequential meanings)\n",
    "#https://pytorch.org/docs/master/generated/torch.nn.LSTM.html\n",
    "\n",
    "#embed_dim=10\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, cnn_dim, hidden_size, vocab_size, num_layers=1):\n",
    "        super(LSTM, self).__init__()\n",
    "        '''\n",
    "        # define the properties\n",
    "        self.cnn_dim = cnn_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "        \n",
    "        # lstm cell\n",
    "        self.lstm_cell = nn.LSTMCell(input_size=self.vocab_size, hidden_size=hidden_size)\n",
    "    \n",
    "        # output fully connected layer\n",
    "        self.fc_in = nn.Linear(in_features=self.cnn_dim, out_features=self.vocab_size)\n",
    "        self.fc_out = nn.Linear(in_features=self.hidden_size, out_features=self.vocab_size)\n",
    "    \n",
    "        # embedding layer\n",
    "        #self.embed = nn.Embedding(num_embeddings=self.vocab_size, embedding_dim=self.vocab_size)\n",
    "        self.embed = nn.Embedding(num_embeddings=self.vocab_size, embedding_dim=embed_dim)\n",
    "        # activations\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        #??\n",
    "        '''\n",
    "        # define properties\n",
    "        self.cnn_dim = cnn_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "        \n",
    "        # lstm module\n",
    "        self.lstm = nn.LSTM(cnn_dim, hidden_size, bidirectional=True)\n",
    "        self.embedding = nn.Linear(hidden_size*2, vocab_size)\n",
    "        #self.lstm_cell = nn.LSTMCell()\n",
    "        \n",
    "        #fc layer for output\n",
    "        self.fc_out = nn.Linear(hidden_size,vocab_size)\n",
    "        \n",
    "        #activation\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, features):\n",
    "        \n",
    "        outputs, _ = self.lstm(features)\n",
    "        T, b, h = outputs.size()\n",
    "        outputs = outputs.view(T*b,h)\n",
    "        \n",
    "        output = self.embedding(outputs)\n",
    "        output = output.view(T,b,-1)\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        batch_size = features.size(0)\n",
    "        #print(batch_size)\n",
    "        cnn_dim = features.size(1)\n",
    "        #print(cnn_dim)\n",
    "        #initialize h0,c0\n",
    "        hidden_state = torch.zeros((batch_size, self.hidden_size)).cuda()\n",
    "        cell_state = torch.zeros((batch_size, self.hidden_size)).cuda()\n",
    "    \n",
    "        # define the output tensor placeholder\n",
    "        outputs = torch.empty((batch_size, captions.size(1), self.vocab_size)).cuda()\n",
    "\n",
    "        # embed the captions\n",
    "        captions_embed = self.embed(captions)\n",
    "        '''\n",
    "        #TODO\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TM2vL2PTFeEt"
   },
   "source": [
    "Problem 2: \n",
    "\n",
    "*   1.Connect CNN model to the designed LSTM model.\n",
    "*   2.Replace ResNet to your own CNN model from Assignment3.\n",
    "\n",
    "\n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''my betternet from AS3'''\n",
    "class Inception(nn.Module):\n",
    "    def __init__(self, in_planes, n1x1, n3x3red, n3x3, n5x5red, n5x5, pool_planes):\n",
    "        super(Inception, self).__init__()\n",
    "        # 1x1 conv branch\n",
    "        self.b1 = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, n1x1, kernel_size=1),\n",
    "            nn.BatchNorm2d(n1x1),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        self.b2 = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, n3x3red, kernel_size=1),\n",
    "            nn.BatchNorm2d(n3x3red),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(n3x3red, n3x3, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n3x3),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        self.b3 = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, n5x5red, kernel_size=1),\n",
    "            nn.BatchNorm2d(n5x5red),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(n5x5red, n5x5, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(n5x5),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(n5x5, n5x5, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(n5x5),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        self.b4 = nn.Sequential(\n",
    "            nn.MaxPool2d(3, stride=1, padding=1),\n",
    "            nn.Conv2d(in_planes, pool_planes, kernel_size=1),\n",
    "            nn.BatchNorm2d(pool_planes),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        y1 = self.b1(x)\n",
    "        y2 = self.b2(x)\n",
    "        y3 = self.b3(x)\n",
    "        y4 = self.b4(x)\n",
    "        return torch.cat([y1,y2,y3,y4], 1)\n",
    "    \n",
    "class BetterNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BetterNet, self).__init__()        \n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1,out_channels=64,kernel_size=7,stride=1,padding=3),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(3,2,1)\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64,out_channels=64,kernel_size=1,stride=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(in_channels=64,out_channels=192,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(3,2,1)\n",
    "        )\n",
    "        self.incep_block1 = nn.Sequential(\n",
    "            Inception(192,64,96,128,16,32,32),\n",
    "            Inception(256,128,128,192,32,96,64),\n",
    "            nn.MaxPool2d(3,2,1)\n",
    "        )        \n",
    "        self.incep_block2 = nn.Sequential(\n",
    "            Inception(480,192,96,208,16,48,64),\n",
    "            Inception(512,160,112,224,24,64,64),\n",
    "            Inception(512,128,128,256,24,64,64),\n",
    "            Inception(512,112,144,288,32,64,64),\n",
    "            Inception(528,256,160,320,32,128,128),\n",
    "            nn.MaxPool2d(3,2,1)\n",
    "        )        \n",
    "        self.incep_block3 = nn.Sequential(\n",
    "            Inception(832,256,160,320,32,128,128),\n",
    "            Inception(832,384,192,384,48,128,128),\n",
    "            nn.AvgPool2d(kernel_size=4)\n",
    "        )        \n",
    "        self.fc_block = nn.Sequential(\n",
    "            nn.Linear(1024,512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512,ALL_CHAR_SET_LEN*MAX_CAPTCHA)\n",
    "           # nn.ReLU(True),\n",
    "           # nn.Linear(64,10)\n",
    "        )        \n",
    "    def forward(self, x):\n",
    "        x=self.block1(x)\n",
    "        x=self.block2(x)\n",
    "        x=self.incep_block1(x)\n",
    "        x=self.incep_block2(x)\n",
    "        x=self.incep_block3(x)\n",
    "        #x = x.view(-1,1024)\n",
    "        #x=self.fc_block(x)\n",
    "        out=x\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OwgpQ1aiFq2a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nloss_func = nn.MultiLabelSoftMarginLoss()\\ncnn_optim = torch.optim.Adam(betternet.parameters(), lr=0.001)\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"ResNet\n",
    "\n",
    "#CNN\n",
    "betternet = resnet.resnet18(pretrained=False)\n",
    "betternet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "betternet.fc = nn.Linear(in_features=512, out_features=ALL_CHAR_SET_LEN*MAX_CAPTCHA, bias=True)\n",
    "betternet = betternet.to(device)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# CNN-RNN connected model\n",
    "\n",
    "hidden_size=8\n",
    "vocab_size=37\n",
    "\n",
    "class CRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, vocab_size, num_layers=1):\n",
    "        super(CRNN, self).__init__()\n",
    "        self.cnn = BetterNet()\n",
    "        self.LSTM = LSTM(1024,hidden_size,vocab_size,num_layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        conv_out = self.cnn(x)\n",
    "        b,c,h,w = conv_out.size()\n",
    "        conv_out = conv_out.squeeze(2) #h must be 1\n",
    "        conv_out = conv_out.permute(2,0,1) #[w,b,c]\n",
    "        \n",
    "        rnn_out = self.LSTM(conv_out)\n",
    "        output = F.log_softmax(output, dim=2)\n",
    "        \n",
    "        #rnn_in = conv_out.view(conv_out.size()[0],vocab_size,-1)\n",
    "        #rnn_out = LSTM(rnn_in)\n",
    "        \n",
    "        return output\n",
    "\n",
    "'''\n",
    "# LSTM\n",
    "cnn_dim=512 #resnet18-512\n",
    "hidden_size=8\n",
    "vocab_size=37 #ALL_CHAR_SET_LEN\n",
    "lstm = LSTM(cnn_dim=cnn_dim, hidden_size=hidden_size, vocab_size=vocab_size)\n",
    "lstm = lstm.to(device)\n",
    "'''\n",
    "\n",
    "crnn = CRNN(hidden_size,vocab_size,1)\n",
    "crnn = crnn.to(device)\n",
    "\n",
    "loss_func = nn.MultiLabelSoftMarginLoss()\n",
    "crnn_optim = torch.optim.Adam(crnn.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "'''\n",
    "loss_func = nn.MultiLabelSoftMarginLoss()\n",
    "cnn_optim = torch.optim.Adam(betternet.parameters(), lr=0.001)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F0uCexwRHsNz"
   },
   "source": [
    "Problem3: Find hyper-parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ibfVzKZeH1yC"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'betternet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-74411668e6c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mlabel_oh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_oh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_oh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbetternet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_oh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mcnn_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'betternet' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"TRAINING\"\"\"\n",
    "print_interval = 5\n",
    "max_epoch = 1000\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    for step, i in enumerate(train_dl):\n",
    "        img, label_oh, label = i\n",
    "        img = Variable(img).cuda()\n",
    "        label_oh = Variable(label_oh.float()).cuda()\n",
    "        batch_size, _ = label_oh.shape\n",
    "        \n",
    "        #pred, feature = betternet(img)\n",
    "        \n",
    "        pred = crnn(img)\n",
    "        \n",
    "        pred_resized = pred.reshape([batch_size,1,-1])\n",
    "        pred_resized = pred_resized.squeeze(1)\n",
    "        \n",
    "        \n",
    "        loss = loss_func(pred_resized, label_oh)\n",
    "        #cnn_optim.zero_grad()\n",
    "        crnn_optim.zero_grad()\n",
    "        loss.backward()\n",
    "        crnn_optim.step()\n",
    "        #cnn_optim.step() #TODO\n",
    "        \n",
    "##############################################################################\n",
    "#                          IMPLEMENT YOUR CODE                               #\n",
    "##############################################################################\n",
    "\n",
    "##############################################################################\n",
    "#                          END OF YOUR CODE                                  #\n",
    "##############################################################################\n",
    "        if (step+1)%print_interval == 0:\n",
    "            print('epoch:', epoch+1, 'step:', step+1, 'loss:', loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e_uKOpe8IGJk"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'betternet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-876a4e50be07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mbetternet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'betternet' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"TEST\"\"\"\n",
    "def get_char_count(arg1):\n",
    "    c0 = ALL_CHAR_SET[np.argmax(arg1.cpu().tolist()[0:ALL_CHAR_SET_LEN])]\n",
    "    c1 = ALL_CHAR_SET[np.argmax(arg1.cpu().tolist()[ALL_CHAR_SET_LEN:ALL_CHAR_SET_LEN*2])]\n",
    "    c2 = ALL_CHAR_SET[np.argmax(arg1.cpu().tolist()[ALL_CHAR_SET_LEN*2:ALL_CHAR_SET_LEN*3])]\n",
    "    c3 = ALL_CHAR_SET[np.argmax(arg1.cpu().tolist()[ALL_CHAR_SET_LEN*3:ALL_CHAR_SET_LEN*4])]\n",
    "    c4 = ALL_CHAR_SET[np.argmax(arg1.cpu().tolist()[ALL_CHAR_SET_LEN*4:ALL_CHAR_SET_LEN*5])]\n",
    "    c5 = ALL_CHAR_SET[np.argmax(arg1.cpu().tolist()[ALL_CHAR_SET_LEN*5:ALL_CHAR_SET_LEN*6])]\n",
    "    c6 = ALL_CHAR_SET[np.argmax(arg1.cpu().tolist()[ALL_CHAR_SET_LEN*6:ALL_CHAR_SET_LEN*7])]\n",
    "    return c0, c1, c2,c3, c4, c5, c6 \n",
    " \n",
    "\n",
    "\n",
    "char_correct = 0\n",
    "word_correct = 0\n",
    "total = 0\n",
    "\n",
    "betternet.eval()\n",
    "lstm.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step, (img, label_oh, label) in enumerate(test_dl):\n",
    "        char_count =0\n",
    "        img = Variable(img).cuda()\n",
    "        label_oh = Variable(label_oh.float()).cuda()\n",
    "        pred, feature = betternet(img) #TODO\n",
    "\n",
    "        label_len = label[0]\n",
    "        pred = pred.squeeze(0)\n",
    "        label_oh = label_oh.squeeze(0)\n",
    "        \n",
    "        c0,c1,c2,c3,c4,c5,c6 = get_char_count(pred.squeeze()) \n",
    "        d0,d1,d2,d3,d4,d5,d6 = get_char_count(label_oh) \n",
    "         \n",
    "        c = '%s%s%s%s%s%s%s' % (c0, c1, c2, c3, c4, c5, c6)\n",
    "        d = '%s%s%s%s%s%s%s' % (d0, d1, d2, d3, d4, d5, d6)\n",
    "    \n",
    "        char_count += (c0==d0)+(c1==d1)+(c2==d2)+(c3==d3)+(c4==d4)+(c5==d5)+(c6==d6)\n",
    "        char_correct += char_count\n",
    "\n",
    "        if(bool(str(label[0]) in str(c))):\n",
    "            word_correct+=1\n",
    "\n",
    "        total += 1\n",
    "       \n",
    "print(100/7*char_correct/total)\n",
    "print(100*word_correct/total)\n",
    "\"\"\"END TEST\"\"\""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
