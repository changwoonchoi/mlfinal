{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D0zuYQzwiO8Z"
   },
   "source": [
    "# M2608.001300 Machine Learning<br> Assignment #5 Final Projects (Pytorch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cap2TxT : An End-to-End Hybrid Neural Network for Captcha Image Text Sequence Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\">\n",
    "Changwoon Choi.<br>\n",
    "SNU ECE.<br>\n",
    "2014-17733<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CJfG1l3RC_c3"
   },
   "source": [
    "For code simplication of this main.ipynb file, I added some python files for simple calculation or transformation at current directory.<br> (those codes are also submitted with this main.ipynb file with maintaining the directory hierarchy.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "M9yv4oGGDbmJ",
    "outputId": "76b24c10-0f36-407e-9bb7-2c9ce3b5edff"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from torch.nn import CTCLoss\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import dataset\n",
    "import utils\n",
    "import params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "acvGcUAaEkxe"
   },
   "source": [
    "Load datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "UcPk4u8qGZHB",
    "outputId": "5b4bfcbc-c731-4704-ae17-649e9f6d16ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f895bee97d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "alphabet='0123456789abcdefghijklmnopqrstuvwxyz'\n",
    "NUMBER = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "ALPHABET = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "NONE = ['NONE'] # label for empty space\n",
    "ALL_CHAR_SET = NUMBER + ALPHABET + NONE\n",
    "ALL_CHAR_SET_LEN = len(ALL_CHAR_SET)\n",
    "MAX_CAPTCHA = 7\n",
    "\n",
    "def encode(a):\n",
    "    onehot = [0]*ALL_CHAR_SET_LEN\n",
    "    idx = ALL_CHAR_SET.index(a)\n",
    "    onehot[idx] += 1\n",
    "    return onehot\n",
    "\n",
    "class Mydataset(Dataset):\n",
    "    def __init__(self, img_path, label_path, is_train=True, transform=None):\n",
    "        self.path = img_path\n",
    "        self.label_path = label_path\n",
    "        if is_train: \n",
    "            self.img = os.listdir(self.path)[:10000]\n",
    "            self.labels = open(self.label_path, 'r').read().split('\\n')[:-1][:10000]\n",
    "        else: \n",
    "            self.img = os.listdir(self.path)[:1000]\n",
    "            self.labels = open(self.label_path, 'r').read().split('\\n')[:-1][:1000]\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.max_length = MAX_CAPTCHA\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img[idx]\n",
    "        img = Image.open(f'{self.path}/{self.img[idx]}')\n",
    "        img = img.convert('L')\n",
    "        label = self.labels[idx]\n",
    "        label_oh = []\n",
    "        \n",
    "        for i in range(self.max_length):\n",
    "            if i < len(label):\n",
    "                label_oh += encode(label[i])\n",
    "            else:\n",
    "                #label_oh += [0]*ALL_CHAR_SET_LEN\n",
    "                label_oh += encode('NONE')\n",
    "            \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, np.array(label_oh), label\n",
    "    def __len__(self):\n",
    "        return len(self.img)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize([160, 60]),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "random.seed(1234)\n",
    "np.random.seed(1234)\n",
    "torch.manual_seed(1234)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "EFtlQyubGJZb",
    "outputId": "4697c0a5-d24a-4e05-f226-14021b625f5e"
   },
   "outputs": [],
   "source": [
    "gPath = './'\n",
    "train_ds = Mydataset(gPath+'Data/train/', gPath+'Data/train.txt',transform=transform)\n",
    "test_ds = Mydataset(gPath+'Data/test/', gPath+'Data/test.txt',False, transform)\n",
    "train_dl = DataLoader(train_ds, batch_size=64, num_workers=4)\n",
    "test_dl = DataLoader(test_ds, batch_size=1, num_workers=4)\n",
    "my_train_loader=torch.utils.data.DataLoader(dataset.lmdbDataset('Data/train_prepared'), batch_size=32,shuffle=True, sampler=None, num_workers=4, collate_fn=dataset.alignCollate(imgH=64,imgW=160, keep_ratio=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare dataset (the python files below should be executed only once.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python misc.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python misc_2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python misc_3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create_dataset.py:14: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\r\n",
      "  imageBuf = np.fromstring(imageBin, dtype=np.uint8)\r\n"
     ]
    }
   ],
   "source": [
    "!python create_dataset.py --out Data/train_prepared --folder Data/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ka5SgX6VIWcG"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tJaHW3wSENjY"
   },
   "source": [
    "Problem 1: Design LSTM model for captcha image recognition. (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "rHEe3XmBFQHq",
    "outputId": "5b4bfcbc-c731-4704-ae17-649e9f6d16ac"
   },
   "outputs": [],
   "source": [
    "class ONE_LAYER_LSTM(nn.Module):\n",
    "    def __init__(self, dim_in, dim_hidden, dim_out):\n",
    "        super(ONE_LAYER_LSTM,self).__init__()\n",
    "        self.lstm = nn.LSTM(dim_in, dim_hidden, bidirectional=True)\n",
    "        self.fc_out = nn.Linear(2*dim_hidden, dim_out)\n",
    "    def forward(self, features):\n",
    "        tmp, _ = self.lstm(features)\n",
    "        T,b,h = tmp.size()\n",
    "        tmp = tmp.view(T*b,h)\n",
    "        output = self.fc_out(tmp)\n",
    "        output = output.view(T,b,-1)\n",
    "        return output\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, cnn_dim, hidden_size, classnum, num_layers=2):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstmnet = nn.Sequential(ONE_LAYER_LSTM(cnn_dim, hidden_size, hidden_size),\n",
    "                                    ONE_LAYER_LSTM(hidden_size,hidden_size, classnum))\n",
    "        \n",
    "    def forward(self, features):\n",
    "        output = self.lstmnet(features)\n",
    "        output = F.log_softmax(output,dim=2)\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TM2vL2PTFeEt"
   },
   "source": [
    "Problem 2: \n",
    "\n",
    "*   1.Connect CNN model to the designed LSTM model.\n",
    "*   2.Replace ResNet to your own CNN model from Assignment3.\n",
    "\n",
    "\n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial1\n",
    "'''my betternet from AS3'''\n",
    "\n",
    "class Inception(nn.Module):\n",
    "    def __init__(self, in_planes, n1x1, n3x3red, n3x3, n5x5red, n5x5, pool_planes):\n",
    "        super(Inception, self).__init__()\n",
    "        # 1x1 conv branch\n",
    "        self.b1 = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, n1x1, kernel_size=1),\n",
    "            nn.BatchNorm2d(n1x1),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        self.b2 = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, n3x3red, kernel_size=1),\n",
    "            nn.BatchNorm2d(n3x3red),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(n3x3red, n3x3, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n3x3),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        self.b3 = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, n5x5red, kernel_size=1),\n",
    "            nn.BatchNorm2d(n5x5red),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(n5x5red, n5x5, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(n5x5),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(n5x5, n5x5, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(n5x5),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        self.b4 = nn.Sequential(\n",
    "            nn.MaxPool2d(3, stride=1, padding=1),\n",
    "            nn.Conv2d(in_planes, pool_planes, kernel_size=1),\n",
    "            nn.BatchNorm2d(pool_planes),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        y1 = self.b1(x)\n",
    "        y2 = self.b2(x)\n",
    "        y3 = self.b3(x)\n",
    "        y4 = self.b4(x)\n",
    "        return torch.cat([y1,y2,y3,y4], 1)\n",
    "    \n",
    "class BetterNet_1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BetterNet_1, self).__init__()        \n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1,out_channels=64,kernel_size=7,stride=1,padding=3),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(3,2,1)\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64,out_channels=64,kernel_size=1,stride=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(in_channels=64,out_channels=192,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(3,2,1)\n",
    "        )\n",
    "        self.incep_block1 = nn.Sequential(\n",
    "            Inception(192,64,96,128,16,32,32),\n",
    "            Inception(256,128,128,192,32,96,64),\n",
    "            nn.MaxPool2d(3,2,1)\n",
    "        )        \n",
    "        self.incep_block2 = nn.Sequential(\n",
    "            Inception(480,192,96,208,16,48,64),\n",
    "            Inception(512,160,112,224,24,64,64),\n",
    "            Inception(512,128,128,256,24,64,64),\n",
    "            Inception(512,112,144,288,32,64,64),\n",
    "            Inception(528,256,160,320,32,128,128),\n",
    "            nn.MaxPool2d(3,2,1)\n",
    "        )        \n",
    "        self.incep_block3 = nn.Sequential(\n",
    "            Inception(832,256,160,320,32,128,128),\n",
    "            Inception(832,384,192,384,48,128,128),\n",
    "            nn.AvgPool2d(kernel_size=4,stride=1,padding=0)\n",
    "        )        \n",
    "        self.fc_block = nn.Sequential(\n",
    "            nn.Linear(1024,512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512,ALL_CHAR_SET_LEN*MAX_CAPTCHA)\n",
    "           # nn.ReLU(True),\n",
    "           # nn.Linear(64,10)\n",
    "        )        \n",
    "    def forward(self, x):\n",
    "        x=self.block1(x)\n",
    "        x=self.block2(x)\n",
    "        x=self.incep_block1(x)\n",
    "        x=self.incep_block2(x)\n",
    "        x=self.incep_block3(x)\n",
    "        #print('cnn 5:',end='')\n",
    "        #print(x.shape)\n",
    "        #x = x.view(-1,1024)\n",
    "        #x=self.fc_block(x)\n",
    "        out=x\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial 2\n",
    "'''my betternet from AS3'''\n",
    "class BetterNet_2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BetterNet_2, self).__init__()\n",
    "        \n",
    "        self.cnn1=nn.Sequential()\n",
    "        self.cnn1.add_module('conv1', nn.Conv2d(1,64,3,1,1))\n",
    "        self.cnn1.add_module('relu1', nn.ReLU(True))\n",
    "        self.cnn1.add_module('pooling1', nn.MaxPool2d(2,2))\n",
    "        \n",
    "        self.cnn2=nn.Sequential()\n",
    "        self.cnn2.add_module('conv2', nn.Conv2d(64,128,3,1,1))\n",
    "        self.cnn2.add_module('relu2', nn.ReLU(True))\n",
    "        self.cnn2.add_module('pooling2', nn.MaxPool2d(2,2))\n",
    "        \n",
    "        self.cnn3=nn.Sequential()\n",
    "        self.cnn3.add_module('conv3', nn.Conv2d(128,256,3,1,1))\n",
    "        self.cnn3.add_module('batchnorm', nn.BatchNorm2d(256))\n",
    "        self.cnn3.add_module('relu3', nn.ReLU(True))\n",
    "               \n",
    "        self.cnn4=nn.Sequential()\n",
    "        self.cnn4.add_module('conv4', nn.Conv2d(256,256,3,1,1))\n",
    "        self.cnn4.add_module('relu4', nn.ReLU(True))\n",
    "        self.cnn4.add_module('pooling4', nn.MaxPool2d((2,2),(2,1),(0,1)))\n",
    "        \n",
    "        self.cnn5=nn.Sequential()\n",
    "        self.cnn5.add_module('conv5', nn.Conv2d(256,512,3,1,1))\n",
    "        self.cnn5.add_module('batchnorm', nn.BatchNorm2d(512))\n",
    "        self.cnn5.add_module('relu5', nn.ReLU(True))\n",
    "\n",
    "        self.cnn6=nn.Sequential()\n",
    "        self.cnn6.add_module('conv6', nn.Conv2d(512,512,3,1,1))\n",
    "        self.cnn6.add_module('relu6', nn.ReLU(True))\n",
    "        self.cnn6.add_module('pooling6', nn.MaxPool2d((2,2),(2,1),(0,1)))\n",
    "        \n",
    "        self.cnn7=nn.Sequential()\n",
    "        self.cnn7.add_module('conv7', nn.Conv2d(512,512,2,1,0))\n",
    "        self.cnn7.add_module('batchnorm', nn.BatchNorm2d(512))\n",
    "        self.cnn7.add_module('relu7', nn.ReLU(True))\n",
    "        self.cnn7.add_module('pooling7', nn.AvgPool2d(kernel_size=3,stride=1))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out=self.cnn1(x)\n",
    "        out=self.cnn2(out)\n",
    "        out=self.cnn3(out)\n",
    "        out=self.cnn4(out)\n",
    "        out=self.cnn5(out)\n",
    "        out=self.cnn6(out)\n",
    "        out=self.cnn7(out)\n",
    "        return out\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_normalize(net):\n",
    "    a=net.__class__.__name__\n",
    "    if a.find('Conv') != -1:\n",
    "        net.weight.data.normal_(0,0.02)\n",
    "    elif a.find('BatchNorm') !=-1:\n",
    "        net.weight.data.normal_(1,0.02)\n",
    "        net.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OwgpQ1aiFq2a"
   },
   "outputs": [],
   "source": [
    "# my CNN-RNN fusioned model, Cap2TxT Network\n",
    "# trial 1,2\n",
    "vocab_size = len(alphabet)+1\n",
    "\n",
    "class Cap2TxT(nn.Module):\n",
    "    def __init__(self, hidden_size, class_num, num_layers=2):\n",
    "        super(Cap2TxT, self).__init__()\n",
    "        #self.cnn = BetterNet_2()\n",
    "        self.cnn = BetterNet_1()\n",
    "        #self.rnn = LSTM(512, hidden_size, class_num,num_layers)\n",
    "        self.rnn = LSTM(1024, hidden_size, class_num, num_layers)\n",
    "    def forward(self, x):\n",
    "        \n",
    "        features = self.cnn(x)\n",
    "        #print(features.size())\n",
    "        b,c,h,w = features.size()\n",
    "        features = features.squeeze(2)\n",
    "        features = features.permute(2,0,1)\n",
    "        output = self.rnn(features)\n",
    "        return output\n",
    "\n",
    "\n",
    "hidden_size=256\n",
    "batch_size = 32\n",
    "lr = 0.0001\n",
    "\n",
    "image = torch.FloatTensor(batch_size, 3, 64, 64)\n",
    "text = torch.LongTensor(batch_size * 5)\n",
    "length = torch.LongTensor(batch_size)\n",
    "\n",
    "net = Cap2TxT(hidden_size,vocab_size,2)\n",
    "net.apply(weight_normalize)\n",
    "\n",
    "\n",
    "converter = utils.strLabelConverter(alphabet)\n",
    "loss_func = CTCLoss()\n",
    "loss_avg=utils.averager()\n",
    "\n",
    "loss_func = loss_func.cuda()\n",
    "image=image.cuda()\n",
    "text=text.cuda()\n",
    "net=net.cuda()\n",
    "\n",
    "image=Variable(image)\n",
    "text=Variable(text)\n",
    "length=Variable(length)\n",
    "\n",
    "cap2txt_optim = optim.RMSprop(net.parameters(),lr)\n",
    "#cap2txt_optim = optim.Adam(net.parameters(),lr,betas=(0.5,0.999))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F0uCexwRHsNz"
   },
   "source": [
    "Problem3: Find hyper-parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ibfVzKZeH1yC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0, Loss : 0.122119\n",
      "saved\n",
      "epoch : 1, Loss : 0.114869\n",
      "epoch : 2, Loss : 0.097594\n",
      "epoch : 3, Loss : 0.080764\n",
      "saved\n",
      "epoch : 4, Loss : 0.063179\n",
      "epoch : 5, Loss : 0.047502\n",
      "epoch : 6, Loss : 0.036180\n",
      "saved\n",
      "epoch : 7, Loss : 0.029120\n",
      "epoch : 8, Loss : 0.022502\n",
      "epoch : 9, Loss : 0.018161\n",
      "saved\n",
      "epoch : 10, Loss : 0.015251\n",
      "epoch : 11, Loss : 0.012913\n",
      "epoch : 12, Loss : 0.010618\n",
      "saved\n",
      "epoch : 13, Loss : 0.009241\n",
      "epoch : 14, Loss : 0.007873\n",
      "epoch : 15, Loss : 0.007073\n",
      "saved\n",
      "epoch : 16, Loss : 0.006063\n",
      "epoch : 17, Loss : 0.005284\n",
      "epoch : 18, Loss : 0.005042\n",
      "saved\n",
      "epoch : 19, Loss : 0.006001\n",
      "epoch : 20, Loss : 0.003667\n",
      "epoch : 21, Loss : 0.004812\n",
      "saved\n",
      "epoch : 22, Loss : 0.004109\n",
      "epoch : 23, Loss : 0.003277\n",
      "epoch : 24, Loss : 0.002493\n",
      "saved\n",
      "epoch : 25, Loss : 0.002988\n",
      "epoch : 26, Loss : 0.002113\n",
      "epoch : 27, Loss : 0.002185\n",
      "saved\n",
      "epoch : 28, Loss : 0.002145\n",
      "epoch : 29, Loss : 0.001959\n",
      "epoch : 30, Loss : 0.001460\n",
      "saved\n",
      "epoch : 31, Loss : 0.001873\n",
      "epoch : 32, Loss : 0.001267\n",
      "epoch : 33, Loss : 0.001840\n",
      "saved\n",
      "epoch : 34, Loss : 0.001210\n",
      "epoch : 35, Loss : 0.001237\n",
      "epoch : 36, Loss : 0.001227\n",
      "saved\n",
      "epoch : 37, Loss : 0.001209\n",
      "epoch : 38, Loss : 0.001951\n",
      "epoch : 39, Loss : 0.001198\n",
      "saved\n",
      "epoch : 40, Loss : 0.001224\n",
      "epoch : 41, Loss : 0.001121\n",
      "epoch : 42, Loss : 0.000937\n",
      "saved\n",
      "epoch : 43, Loss : 0.001030\n",
      "epoch : 44, Loss : 0.000963\n",
      "epoch : 45, Loss : 0.000937\n",
      "saved\n",
      "epoch : 46, Loss : 0.000851\n",
      "epoch : 47, Loss : 0.000892\n",
      "epoch : 48, Loss : 0.001009\n",
      "saved\n",
      "epoch : 49, Loss : 0.000605\n",
      "epoch : 50, Loss : 0.000720\n",
      "epoch : 51, Loss : 0.000804\n",
      "saved\n",
      "epoch : 52, Loss : 0.000705\n",
      "epoch : 53, Loss : 0.000582\n",
      "epoch : 54, Loss : 0.000968\n",
      "saved\n",
      "epoch : 55, Loss : 0.000708\n",
      "epoch : 56, Loss : 0.000460\n",
      "epoch : 57, Loss : 0.000702\n",
      "saved\n",
      "epoch : 58, Loss : 0.000559\n",
      "epoch : 59, Loss : 0.000790\n",
      "epoch : 60, Loss : 0.000488\n",
      "saved\n",
      "epoch : 61, Loss : 0.000591\n",
      "epoch : 62, Loss : 0.000427\n",
      "epoch : 63, Loss : 0.000700\n",
      "saved\n",
      "epoch : 64, Loss : 0.000586\n",
      "epoch : 65, Loss : 0.000511\n",
      "epoch : 66, Loss : 0.000597\n",
      "saved\n",
      "epoch : 67, Loss : 0.000408\n",
      "epoch : 68, Loss : 0.000604\n",
      "epoch : 69, Loss : 0.000387\n",
      "saved\n",
      "epoch : 70, Loss : 0.000646\n",
      "epoch : 71, Loss : 0.000288\n",
      "epoch : 72, Loss : 0.000513\n",
      "saved\n",
      "epoch : 73, Loss : 0.000540\n",
      "epoch : 74, Loss : 0.000351\n",
      "epoch : 75, Loss : 0.000472\n",
      "saved\n",
      "epoch : 76, Loss : 0.000366\n",
      "epoch : 77, Loss : 0.000437\n",
      "epoch : 78, Loss : 0.000225\n",
      "saved\n",
      "epoch : 79, Loss : 0.000461\n",
      "epoch : 80, Loss : 0.000365\n",
      "epoch : 81, Loss : 0.000724\n",
      "saved\n",
      "epoch : 82, Loss : 0.000215\n",
      "epoch : 83, Loss : 0.000304\n",
      "epoch : 84, Loss : 0.000433\n",
      "saved\n",
      "epoch : 85, Loss : 0.000232\n",
      "epoch : 86, Loss : 0.000425\n",
      "epoch : 87, Loss : 0.000364\n",
      "saved\n",
      "epoch : 88, Loss : 0.000310\n",
      "epoch : 89, Loss : 0.000294\n",
      "epoch : 90, Loss : 0.000261\n",
      "saved\n",
      "epoch : 91, Loss : 0.000372\n",
      "epoch : 92, Loss : 0.000369\n",
      "epoch : 93, Loss : 0.000484\n",
      "saved\n",
      "epoch : 94, Loss : 0.000230\n",
      "epoch : 95, Loss : 0.000387\n",
      "epoch : 96, Loss : 0.000344\n",
      "saved\n",
      "epoch : 97, Loss : 0.000297\n",
      "epoch : 98, Loss : 0.000328\n",
      "epoch : 99, Loss : 0.000233\n",
      "saved\n",
      "epoch : 100, Loss : 0.000193\n",
      "epoch : 101, Loss : 0.000325\n",
      "epoch : 102, Loss : 0.000212\n",
      "saved\n",
      "epoch : 103, Loss : 0.000386\n",
      "epoch : 104, Loss : 0.000353\n",
      "epoch : 105, Loss : 0.000260\n",
      "saved\n",
      "epoch : 106, Loss : 0.000410\n",
      "epoch : 107, Loss : 0.000224\n",
      "epoch : 108, Loss : 0.000171\n",
      "saved\n",
      "epoch : 109, Loss : 0.000159\n",
      "epoch : 110, Loss : 0.000283\n",
      "epoch : 111, Loss : 0.000188\n",
      "saved\n",
      "epoch : 112, Loss : 0.000310\n",
      "epoch : 113, Loss : 0.000279\n",
      "epoch : 114, Loss : 0.000157\n",
      "saved\n",
      "epoch : 115, Loss : 0.000337\n",
      "epoch : 116, Loss : 0.000213\n",
      "epoch : 117, Loss : 0.000228\n",
      "saved\n",
      "epoch : 118, Loss : 0.000202\n",
      "epoch : 119, Loss : 0.000349\n",
      "epoch : 120, Loss : 0.000037\n",
      "saved\n",
      "epoch : 121, Loss : 0.000484\n",
      "epoch : 122, Loss : 0.000276\n",
      "epoch : 123, Loss : 0.000194\n",
      "saved\n",
      "epoch : 124, Loss : 0.000227\n",
      "epoch : 125, Loss : 0.000301\n",
      "epoch : 126, Loss : 0.000209\n",
      "saved\n",
      "epoch : 127, Loss : 0.000220\n",
      "epoch : 128, Loss : 0.000351\n",
      "epoch : 129, Loss : 0.000202\n",
      "saved\n",
      "epoch : 130, Loss : 0.000110\n",
      "epoch : 131, Loss : 0.000356\n",
      "epoch : 132, Loss : 0.000171\n",
      "saved\n",
      "epoch : 133, Loss : 0.000146\n",
      "epoch : 134, Loss : 0.000214\n",
      "epoch : 135, Loss : 0.000160\n",
      "saved\n",
      "epoch : 136, Loss : 0.000323\n",
      "epoch : 137, Loss : 0.000179\n",
      "epoch : 138, Loss : 0.000179\n",
      "saved\n",
      "epoch : 139, Loss : 0.000256\n",
      "epoch : 140, Loss : 0.000145\n",
      "epoch : 141, Loss : 0.000199\n",
      "saved\n",
      "epoch : 142, Loss : 0.000167\n",
      "epoch : 143, Loss : 0.000162\n",
      "epoch : 144, Loss : 0.000221\n",
      "saved\n",
      "epoch : 145, Loss : 0.000113\n",
      "epoch : 146, Loss : 0.000238\n",
      "epoch : 147, Loss : 0.000168\n",
      "saved\n",
      "epoch : 148, Loss : 0.000230\n",
      "epoch : 149, Loss : 0.000193\n",
      "epoch : 150, Loss : 0.000109\n",
      "saved\n",
      "epoch : 151, Loss : 0.000164\n",
      "epoch : 152, Loss : 0.000192\n",
      "epoch : 153, Loss : 0.000210\n",
      "saved\n",
      "epoch : 154, Loss : 0.000051\n",
      "epoch : 155, Loss : 0.000249\n",
      "epoch : 156, Loss : 0.000108\n",
      "saved\n",
      "epoch : 157, Loss : 0.000218\n",
      "epoch : 158, Loss : 0.000199\n",
      "epoch : 159, Loss : 0.000232\n",
      "saved\n",
      "epoch : 160, Loss : 0.000143\n",
      "epoch : 161, Loss : 0.000298\n",
      "epoch : 162, Loss : 0.000084\n",
      "saved\n",
      "epoch : 163, Loss : 0.000184\n",
      "epoch : 164, Loss : 0.000176\n",
      "epoch : 165, Loss : 0.000091\n",
      "saved\n",
      "epoch : 166, Loss : 0.000191\n",
      "epoch : 167, Loss : 0.000073\n",
      "epoch : 168, Loss : 0.000241\n",
      "saved\n",
      "epoch : 169, Loss : 0.000102\n",
      "epoch : 170, Loss : 0.000166\n",
      "epoch : 171, Loss : 0.000158\n",
      "saved\n",
      "epoch : 172, Loss : 0.000104\n",
      "epoch : 173, Loss : 0.000209\n",
      "epoch : 174, Loss : 0.000093\n",
      "saved\n",
      "epoch : 175, Loss : 0.000182\n",
      "epoch : 176, Loss : 0.000179\n",
      "epoch : 177, Loss : 0.000185\n",
      "saved\n",
      "epoch : 178, Loss : 0.000086\n",
      "epoch : 179, Loss : 0.000169\n",
      "epoch : 180, Loss : 0.000153\n",
      "saved\n",
      "epoch : 181, Loss : 0.000232\n",
      "epoch : 182, Loss : 0.000109\n",
      "epoch : 183, Loss : 0.000123\n",
      "saved\n",
      "epoch : 184, Loss : 0.000156\n",
      "epoch : 185, Loss : 0.000127\n",
      "epoch : 186, Loss : 0.000146\n",
      "saved\n",
      "epoch : 187, Loss : 0.000214\n",
      "epoch : 188, Loss : 0.000222\n",
      "epoch : 189, Loss : 0.000117\n",
      "saved\n",
      "epoch : 190, Loss : 0.000116\n",
      "epoch : 191, Loss : 0.000068\n",
      "epoch : 192, Loss : 0.000212\n",
      "saved\n",
      "epoch : 193, Loss : 0.000085\n",
      "epoch : 194, Loss : 0.000118\n",
      "epoch : 195, Loss : 0.000183\n",
      "saved\n",
      "epoch : 196, Loss : 0.000068\n",
      "epoch : 197, Loss : 0.000109\n",
      "epoch : 198, Loss : 0.000140\n",
      "saved\n",
      "epoch : 199, Loss : 0.000161\n",
      "epoch : 200, Loss : 0.000125\n",
      "epoch : 201, Loss : 0.000090\n",
      "saved\n",
      "epoch : 202, Loss : 0.000200\n",
      "epoch : 203, Loss : 0.000028\n",
      "epoch : 204, Loss : 0.000115\n",
      "saved\n",
      "epoch : 205, Loss : 0.000146\n",
      "epoch : 206, Loss : 0.000104\n",
      "epoch : 207, Loss : 0.000146\n",
      "saved\n",
      "epoch : 208, Loss : 0.000010\n",
      "epoch : 209, Loss : 0.000181\n",
      "epoch : 210, Loss : 0.000123\n",
      "saved\n",
      "epoch : 211, Loss : 0.000148\n",
      "epoch : 212, Loss : 0.000164\n",
      "epoch : 213, Loss : 0.000033\n",
      "saved\n",
      "epoch : 214, Loss : 0.000201\n",
      "epoch : 215, Loss : 0.000079\n",
      "epoch : 216, Loss : 0.000168\n",
      "saved\n",
      "epoch : 217, Loss : 0.000092\n",
      "epoch : 218, Loss : 0.000181\n",
      "epoch : 219, Loss : 0.000111\n",
      "saved\n",
      "epoch : 220, Loss : 0.000087\n",
      "epoch : 221, Loss : 0.000076\n",
      "epoch : 222, Loss : 0.000115\n",
      "saved\n",
      "epoch : 223, Loss : 0.000099\n",
      "epoch : 224, Loss : 0.000198\n",
      "epoch : 225, Loss : 0.000068\n",
      "saved\n",
      "epoch : 226, Loss : 0.000201\n",
      "epoch : 227, Loss : 0.000225\n",
      "epoch : 228, Loss : 0.000257\n",
      "saved\n",
      "epoch : 229, Loss : 0.000103\n",
      "epoch : 230, Loss : 0.000160\n",
      "epoch : 231, Loss : 0.000076\n",
      "saved\n",
      "epoch : 232, Loss : 0.000178\n",
      "epoch : 233, Loss : 0.000056\n",
      "epoch : 234, Loss : 0.000188\n",
      "saved\n",
      "epoch : 235, Loss : 0.000160\n",
      "epoch : 236, Loss : 0.000056\n",
      "epoch : 237, Loss : 0.000162\n",
      "saved\n",
      "epoch : 238, Loss : 0.000076\n",
      "epoch : 239, Loss : 0.000105\n",
      "epoch : 240, Loss : 0.000189\n",
      "saved\n",
      "epoch : 241, Loss : 0.000070\n",
      "epoch : 242, Loss : 0.000126\n",
      "epoch : 243, Loss : 0.000110\n",
      "saved\n",
      "epoch : 244, Loss : 0.000150\n",
      "epoch : 245, Loss : 0.000065\n",
      "epoch : 246, Loss : 0.000090\n",
      "saved\n",
      "epoch : 247, Loss : 0.000089\n",
      "epoch : 248, Loss : 0.000060\n",
      "epoch : 249, Loss : 0.000127\n",
      "saved\n",
      "Finished Training\n",
      "Saved Model\n"
     ]
    }
   ],
   "source": [
    "\"\"\"TRAINING\"\"\"\n",
    "\n",
    "SAVE_PATH = './ckpt/'\n",
    "display_interval = 1\n",
    "save_interval=3\n",
    "max_epoch = 250\n",
    "\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    train_it = iter(my_train_loader)\n",
    "    it=0\n",
    "    while it<len(my_train_loader):\n",
    "        for param in net.parameters():\n",
    "            param.requires_grad=True\n",
    "        net.train()\n",
    "        chunk = train_it.next()\n",
    "        img, label = chunk\n",
    "        utils.loadData(image,img)\n",
    "        txt, lth = converter.encode(label)\n",
    "        utils.loadData(text,txt)\n",
    "        utils.loadData(length,lth)\n",
    "        \n",
    "        cap2txt_optim.zero_grad()\n",
    "        predict = net(image)\n",
    "        predict_size = Variable(torch.LongTensor([predict.size(0)] * img.size(0)))\n",
    "        \n",
    "        loss = loss_func(predict,text,predict_size,length)/img.size(0)\n",
    "        loss.backward()\n",
    "        cap2txt_optim.step()\n",
    "        \n",
    "        loss_avg.add(loss)\n",
    "        it+=1\n",
    "        \n",
    "    if epoch%display_interval==0:\n",
    "        print('epoch : %d, Loss : %f' %(epoch,loss_avg.val()))\n",
    "        loss_avg.reset()\n",
    "    if epoch%save_interval==0:\n",
    "        print('saved')\n",
    "        #torch.save(net.state_dict(),SAVE_PATH=\"Cap2TxT_\"+str(epoch)+'pth')\n",
    "        torch.save(net.state_dict(),SAVE_PATH+'Cap2TxT_GoogLe_'+str(epoch)+'.pth')\n",
    "\n",
    "print('Finished Training')\n",
    "torch.save(net.state_dict(),SAVE_PATH+'Cap2TxT'+'_final.pth')\n",
    "print('Saved Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e_uKOpe8IGJk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---char correct---\n",
      "77.55714285714286 %\n",
      "---word correct---\n",
      "62.6 %\n"
     ]
    }
   ],
   "source": [
    "'''Test'''\n",
    "\n",
    "def get_char_count(arg1):\n",
    "    c0 = ALL_CHAR_SET[np.argmax(arg1[0:ALL_CHAR_SET_LEN])]\n",
    "    c1 = ALL_CHAR_SET[np.argmax(arg1[ALL_CHAR_SET_LEN:ALL_CHAR_SET_LEN*2])]\n",
    "    c2 = ALL_CHAR_SET[np.argmax(arg1[ALL_CHAR_SET_LEN*2:ALL_CHAR_SET_LEN*3])]\n",
    "    c3 = ALL_CHAR_SET[np.argmax(arg1[ALL_CHAR_SET_LEN*3:ALL_CHAR_SET_LEN*4])]\n",
    "    c4 = ALL_CHAR_SET[np.argmax(arg1[ALL_CHAR_SET_LEN*4:ALL_CHAR_SET_LEN*5])]\n",
    "    c5 = ALL_CHAR_SET[np.argmax(arg1[ALL_CHAR_SET_LEN*5:ALL_CHAR_SET_LEN*6])]\n",
    "    c6 = ALL_CHAR_SET[np.argmax(arg1[ALL_CHAR_SET_LEN*6:ALL_CHAR_SET_LEN*7])]\n",
    "    return c0, c1, c2,c3, c4, c5, c6 \n",
    "\n",
    "def oh_encoding(a):\n",
    "    label_oh = []\n",
    "    for i in range(7):\n",
    "        if i<len(a):\n",
    "            label_oh+=encode(a[i])\n",
    "        else:\n",
    "            label_oh+=encode('NONE')\n",
    "    return label_oh\n",
    "\n",
    "\n",
    "\n",
    "#model_path = '../final/ckpt/netCRNN_80_266.pth'\n",
    "\n",
    "#best at Cap2TxT\n",
    "model_path ='./ckpt/Cap2TxT_180.pth'\n",
    "\n",
    "#best at Cap2TxT_GoogLeNet\n",
    "\n",
    "\n",
    "image_path = './Data/test/'\n",
    "\n",
    "pred_list =[]\n",
    "\n",
    "class_num = len(alphabet) + 1\n",
    "\n",
    "model = Cap2TxT(hidden_size,class_num)\n",
    "#model = Cap2TxT_2(64,1,class_num,hidden_size)\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "converter = utils.strLabelConverter(alphabet)\n",
    "transformer=dataset.resizeNormalize((160,64))\n",
    "for i in range(1000):\n",
    "    image = Image.open(image_path+str(i)+'.png').convert('L')\n",
    "    image = transformer(image)\n",
    "    if torch.cuda.is_available():\n",
    "        image = image.cuda()\n",
    "    image = image.view(1, *image.size())\n",
    "    image = Variable(image)\n",
    "    preds = model(image)\n",
    "\n",
    "    _, preds = preds.max(2)\n",
    "    preds = preds.transpose(1, 0).contiguous().view(-1)\n",
    "    preds_size = Variable(torch.LongTensor([preds.size(0)]))\n",
    "    pred = converter.decode(preds.data, preds_size.data, raw=False)\n",
    "    pred_list.append(pred)\n",
    "\n",
    "answer='./Data/test.txt'\n",
    "answer_list=list()\n",
    "with open (answer) as f:\n",
    "    for line in f:\n",
    "        answer_list.append(line.rstrip('\\n'))\n",
    "\n",
    "char_correct = 0\n",
    "word_correct = 0\n",
    "total = 0\n",
    "\n",
    "for i in range(1000): # size of test set is 1000\n",
    "    char_count=0\n",
    "    c0,c1,c2,c3,c4,c5,c6 = get_char_count(oh_encoding(pred_list[i]))\n",
    "    d0,d1,d2,d3,d4,d5,d6 = get_char_count(oh_encoding(answer_list[i]))\n",
    "    c = '%s%s%s%s%s%s%s' % (c0, c1, c2, c3, c4, c5, c6)\n",
    "    d = '%s%s%s%s%s%s%s' % (d0, d1, d2, d3, d4, d5, d6)\n",
    "    char_count += (c0==d0)+(c1==d1)+(c2==d2)+(c3==d3)+(c4==d4)+(c5==d5)+(c6==d6)\n",
    "    char_correct += char_count\n",
    "    if(bool(str(answer_list[i]) in str(c))):\n",
    "        word_correct+=1\n",
    "    total += 1\n",
    "\n",
    "print('---char correct---')\n",
    "print(100*(char_correct/(total*7)), end=' ')\n",
    "print('%')\n",
    "print('---word correct---')\n",
    "print(100*word_correct/total, end=' ')\n",
    "print('%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "current...\n",
      "0:36.72857142857143\n",
      "best...\n",
      "0:36.72857142857143\n",
      "------------------------------------\n",
      "current...\n",
      "3:38.2\n",
      "best...\n",
      "3:38.2\n",
      "------------------------------------\n",
      "current...\n",
      "6:36.32857142857143\n",
      "best...\n",
      "3:38.2\n",
      "------------------------------------\n",
      "current...\n",
      "9:101.45714285714286\n",
      "best...\n",
      "9:101.45714285714286\n",
      "------------------------------------\n",
      "current...\n",
      "12:111.01428571428572\n",
      "best...\n",
      "12:111.01428571428572\n",
      "------------------------------------\n",
      "current...\n",
      "15:121.2\n",
      "best...\n",
      "15:121.2\n",
      "------------------------------------\n",
      "current...\n",
      "18:86.57142857142857\n",
      "best...\n",
      "15:121.2\n",
      "------------------------------------\n",
      "current...\n",
      "21:147.22857142857143\n",
      "best...\n",
      "21:147.22857142857143\n",
      "------------------------------------\n",
      "current...\n",
      "24:148.51428571428573\n",
      "best...\n",
      "24:148.51428571428573\n",
      "------------------------------------\n",
      "current...\n",
      "27:138.38571428571427\n",
      "best...\n",
      "24:148.51428571428573\n",
      "------------------------------------\n",
      "current...\n",
      "30:49.800000000000004\n",
      "best...\n",
      "24:148.51428571428573\n",
      "------------------------------------\n",
      "current...\n",
      "33:145.94285714285715\n",
      "best...\n",
      "24:148.51428571428573\n",
      "------------------------------------\n",
      "current...\n",
      "36:144.04285714285714\n",
      "best...\n",
      "24:148.51428571428573\n",
      "------------------------------------\n",
      "current...\n",
      "39:148.78571428571428\n",
      "best...\n",
      "39:148.78571428571428\n",
      "------------------------------------\n",
      "current...\n",
      "42:138.25714285714287\n",
      "best...\n",
      "39:148.78571428571428\n",
      "------------------------------------\n",
      "current...\n",
      "45:146.42857142857144\n",
      "best...\n",
      "39:148.78571428571428\n",
      "------------------------------------\n",
      "current...\n",
      "48:140.45714285714286\n",
      "best...\n",
      "39:148.78571428571428\n",
      "------------------------------------\n",
      "current...\n",
      "51:156.71428571428572\n",
      "best...\n",
      "51:156.71428571428572\n",
      "------------------------------------\n",
      "current...\n",
      "54:146.22857142857143\n",
      "best...\n",
      "51:156.71428571428572\n",
      "------------------------------------\n",
      "current...\n",
      "57:147.77142857142857\n",
      "best...\n",
      "51:156.71428571428572\n",
      "------------------------------------\n",
      "current...\n",
      "60:155.54285714285714\n",
      "best...\n",
      "51:156.71428571428572\n",
      "------------------------------------\n",
      "current...\n",
      "63:152.39999999999998\n",
      "best...\n",
      "51:156.71428571428572\n",
      "------------------------------------\n",
      "current...\n",
      "66:159.8857142857143\n",
      "best...\n",
      "66:159.8857142857143\n",
      "------------------------------------\n",
      "current...\n",
      "69:159.5142857142857\n",
      "best...\n",
      "66:159.8857142857143\n",
      "------------------------------------\n",
      "current...\n",
      "72:157.8857142857143\n",
      "best...\n",
      "66:159.8857142857143\n",
      "------------------------------------\n",
      "current...\n",
      "75:119.07142857142857\n",
      "best...\n",
      "66:159.8857142857143\n",
      "------------------------------------\n",
      "current...\n",
      "78:156.6857142857143\n",
      "best...\n",
      "66:159.8857142857143\n",
      "------------------------------------\n",
      "current...\n",
      "81:159.0857142857143\n",
      "best...\n",
      "66:159.8857142857143\n",
      "------------------------------------\n",
      "current...\n",
      "84:161.24285714285713\n",
      "best...\n",
      "84:161.24285714285713\n",
      "------------------------------------\n",
      "current...\n",
      "87:159.15714285714284\n",
      "best...\n",
      "84:161.24285714285713\n",
      "------------------------------------\n",
      "current...\n",
      "90:158.95714285714286\n",
      "best...\n",
      "84:161.24285714285713\n",
      "------------------------------------\n",
      "current...\n",
      "93:152.27142857142857\n",
      "best...\n",
      "84:161.24285714285713\n",
      "------------------------------------\n",
      "current...\n",
      "96:158.82857142857142\n",
      "best...\n",
      "84:161.24285714285713\n",
      "------------------------------------\n",
      "current...\n",
      "99:157.42857142857144\n",
      "best...\n",
      "84:161.24285714285713\n",
      "------------------------------------\n",
      "current...\n",
      "102:160.4\n",
      "best...\n",
      "84:161.24285714285713\n",
      "------------------------------------\n",
      "current...\n",
      "105:158.48571428571427\n",
      "best...\n",
      "84:161.24285714285713\n",
      "------------------------------------\n",
      "current...\n",
      "108:136.88571428571427\n",
      "best...\n",
      "84:161.24285714285713\n",
      "------------------------------------\n",
      "current...\n",
      "111:155.54285714285714\n",
      "best...\n",
      "84:161.24285714285713\n",
      "------------------------------------\n",
      "current...\n",
      "114:101.55714285714285\n",
      "best...\n",
      "84:161.24285714285713\n",
      "------------------------------------\n",
      "current...\n",
      "117:157.27142857142857\n",
      "best...\n",
      "84:161.24285714285713\n",
      "------------------------------------\n",
      "current...\n",
      "120:161.34285714285716\n",
      "best...\n",
      "120:161.34285714285716\n",
      "------------------------------------\n",
      "current...\n",
      "123:153.42857142857144\n",
      "best...\n",
      "120:161.34285714285716\n",
      "------------------------------------\n",
      "current...\n",
      "126:158.4714285714286\n",
      "best...\n",
      "120:161.34285714285716\n",
      "------------------------------------\n",
      "current...\n",
      "129:158.28571428571428\n",
      "best...\n",
      "120:161.34285714285716\n",
      "------------------------------------\n",
      "current...\n",
      "132:158.89999999999998\n",
      "best...\n",
      "120:161.34285714285716\n",
      "------------------------------------\n",
      "current...\n",
      "135:160.21428571428572\n",
      "best...\n",
      "120:161.34285714285716\n",
      "------------------------------------\n",
      "current...\n",
      "138:156.52857142857144\n",
      "best...\n",
      "120:161.34285714285716\n",
      "------------------------------------\n",
      "current...\n",
      "141:159.64285714285714\n",
      "best...\n",
      "120:161.34285714285716\n",
      "------------------------------------\n",
      "current...\n",
      "144:159.2\n",
      "best...\n",
      "120:161.34285714285716\n",
      "------------------------------------\n",
      "current...\n",
      "147:161.82857142857142\n",
      "best...\n",
      "147:161.82857142857142\n",
      "------------------------------------\n",
      "current...\n",
      "150:162.75714285714287\n",
      "best...\n",
      "150:162.75714285714287\n",
      "------------------------------------\n",
      "current...\n",
      "153:162.8142857142857\n",
      "best...\n",
      "153:162.8142857142857\n",
      "------------------------------------\n",
      "current...\n",
      "156:160.8\n",
      "best...\n",
      "153:162.8142857142857\n",
      "------------------------------------\n",
      "current...\n",
      "159:155.37142857142857\n",
      "best...\n",
      "153:162.8142857142857\n",
      "------------------------------------\n",
      "current...\n",
      "162:158.12857142857143\n",
      "best...\n",
      "153:162.8142857142857\n",
      "------------------------------------\n",
      "current...\n",
      "165:162.14285714285717\n",
      "best...\n",
      "153:162.8142857142857\n",
      "------------------------------------\n",
      "current...\n",
      "168:162.35714285714283\n",
      "best...\n",
      "153:162.8142857142857\n",
      "------------------------------------\n",
      "current...\n",
      "171:161.60000000000002\n",
      "best...\n",
      "153:162.8142857142857\n",
      "------------------------------------\n",
      "current...\n",
      "174:158.4142857142857\n",
      "best...\n",
      "153:162.8142857142857\n",
      "------------------------------------\n",
      "current...\n",
      "177:161.84285714285716\n",
      "best...\n",
      "153:162.8142857142857\n",
      "------------------------------------\n",
      "current...\n",
      "180:162.17142857142858\n",
      "best...\n",
      "153:162.8142857142857\n",
      "------------------------------------\n",
      "current...\n",
      "183:160.98571428571427\n",
      "best...\n",
      "153:162.8142857142857\n",
      "------------------------------------\n",
      "current...\n",
      "186:163.25714285714287\n",
      "best...\n",
      "186:163.25714285714287\n",
      "------------------------------------\n",
      "current...\n",
      "189:158.55714285714285\n",
      "best...\n",
      "186:163.25714285714287\n",
      "------------------------------------\n",
      "current...\n",
      "192:161.14285714285714\n",
      "best...\n",
      "186:163.25714285714287\n",
      "------------------------------------\n",
      "current...\n",
      "195:161.28571428571428\n",
      "best...\n",
      "186:163.25714285714287\n",
      "------------------------------------\n",
      "current...\n",
      "198:150.64285714285714\n",
      "best...\n",
      "186:163.25714285714287\n",
      "------------------------------------\n",
      "current...\n",
      "201:162.87142857142857\n",
      "best...\n",
      "186:163.25714285714287\n",
      "------------------------------------\n",
      "current...\n",
      "204:160.15714285714284\n",
      "best...\n",
      "186:163.25714285714287\n",
      "------------------------------------\n",
      "current...\n",
      "207:162.4\n",
      "best...\n",
      "186:163.25714285714287\n",
      "------------------------------------\n",
      "current...\n",
      "210:161.8\n",
      "best...\n",
      "186:163.25714285714287\n",
      "------------------------------------\n",
      "current...\n",
      "213:162.4714285714286\n",
      "best...\n",
      "186:163.25714285714287\n",
      "------------------------------------\n",
      "current...\n",
      "216:162.89999999999998\n",
      "best...\n",
      "186:163.25714285714287\n",
      "------------------------------------\n",
      "current...\n",
      "219:161.07142857142858\n",
      "best...\n",
      "186:163.25714285714287\n",
      "------------------------------------\n",
      "current...\n",
      "222:157.92857142857144\n",
      "best...\n",
      "186:163.25714285714287\n",
      "------------------------------------\n",
      "current...\n",
      "225:160.9142857142857\n",
      "best...\n",
      "186:163.25714285714287\n",
      "------------------------------------\n",
      "current...\n",
      "228:160.0\n",
      "best...\n",
      "186:163.25714285714287\n",
      "------------------------------------\n",
      "current...\n",
      "231:166.10000000000002\n",
      "best...\n",
      "231:166.10000000000002\n",
      "------------------------------------\n",
      "current...\n",
      "234:164.4142857142857\n",
      "best...\n",
      "231:166.10000000000002\n",
      "------------------------------------\n",
      "current...\n",
      "237:161.0\n",
      "best...\n",
      "231:166.10000000000002\n",
      "------------------------------------\n",
      "current...\n",
      "240:162.94285714285715\n",
      "best...\n",
      "231:166.10000000000002\n",
      "------------------------------------\n",
      "current...\n",
      "243:163.44285714285715\n",
      "best...\n",
      "231:166.10000000000002\n",
      "------------------------------------\n",
      "current...\n",
      "246:162.1142857142857\n",
      "best...\n",
      "231:166.10000000000002\n",
      "------------------------------------\n",
      "current...\n",
      "249:163.85714285714286\n",
      "best...\n",
      "231:166.10000000000002\n"
     ]
    }
   ],
   "source": [
    "'''Find the best weight from my experiment results.'''\n",
    "\n",
    "def get_char_count(arg1):\n",
    "    c0 = ALL_CHAR_SET[np.argmax(arg1[0:ALL_CHAR_SET_LEN])]\n",
    "    c1 = ALL_CHAR_SET[np.argmax(arg1[ALL_CHAR_SET_LEN:ALL_CHAR_SET_LEN*2])]\n",
    "    c2 = ALL_CHAR_SET[np.argmax(arg1[ALL_CHAR_SET_LEN*2:ALL_CHAR_SET_LEN*3])]\n",
    "    c3 = ALL_CHAR_SET[np.argmax(arg1[ALL_CHAR_SET_LEN*3:ALL_CHAR_SET_LEN*4])]\n",
    "    c4 = ALL_CHAR_SET[np.argmax(arg1[ALL_CHAR_SET_LEN*4:ALL_CHAR_SET_LEN*5])]\n",
    "    c5 = ALL_CHAR_SET[np.argmax(arg1[ALL_CHAR_SET_LEN*5:ALL_CHAR_SET_LEN*6])]\n",
    "    c6 = ALL_CHAR_SET[np.argmax(arg1[ALL_CHAR_SET_LEN*6:ALL_CHAR_SET_LEN*7])]\n",
    "    return c0, c1, c2,c3, c4, c5, c6 \n",
    "\n",
    "def oh_encoding(a):\n",
    "    label_oh = []\n",
    "    for i in range(7):\n",
    "        if i<len(a):\n",
    "            label_oh+=encode(a[i])\n",
    "        else:\n",
    "            label_oh+=encode('NONE')\n",
    "    return label_oh\n",
    "\n",
    "\n",
    "\n",
    "#model_path = '../final/ckpt/netCRNN_80_266.pth'\n",
    "\n",
    "#best at Cap2TxT\n",
    "#model_path ='./ckpt/Cap2TxT_180.pth'\n",
    "\n",
    "#best at Cap2TxT_GoogLeNet\n",
    "#model_path = './ckpt/Cap2TxT_final.pth'\n",
    "#model_path = './ckpt/Cap2TxT_GoogLe_150.pth'\n",
    "image_path = './Data/test/'\n",
    "class_num = len(alphabet) + 1\n",
    "converter = utils.strLabelConverter(alphabet)\n",
    "transformer=dataset.resizeNormalize((160,64))\n",
    "\n",
    "answer='./Data/test.txt'\n",
    "answer_list=list()\n",
    "with open (answer) as f:\n",
    "    for line in f:\n",
    "        answer_list.append(line.rstrip('\\n'))\n",
    "\n",
    "#Let's find best fitted model among 0~250 epoch that performs best at test set!\n",
    "\n",
    "max_accuracy = 0\n",
    "best_epoch = 0\n",
    "epoch=0\n",
    "while epoch <250 :\n",
    "    model_path = './ckpt/Cap2TxT_GoogLe_'+str(epoch)+'.pth'\n",
    "    pred_list =[]\n",
    "    model = Cap2TxT(hidden_size,class_num)\n",
    "    #model = Cap2TxT_2(64,1,class_num,hidden_size)\n",
    "    model = model.cuda()\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    \n",
    "    for i in range(1000):\n",
    "        image = Image.open(image_path+str(i)+'.png').convert('L')\n",
    "        image = transformer(image)\n",
    "        if torch.cuda.is_available():\n",
    "            image = image.cuda()\n",
    "        image = image.view(1, *image.size())\n",
    "        image = Variable(image)\n",
    "        preds = model(image)\n",
    "\n",
    "        _, preds = preds.max(2)\n",
    "        preds = preds.transpose(1, 0).contiguous().view(-1)\n",
    "        preds_size = Variable(torch.LongTensor([preds.size(0)]))\n",
    "        pred = converter.decode(preds.data, preds_size.data, raw=False)\n",
    "        pred_list.append(pred)\n",
    "\n",
    "    char_correct = 0\n",
    "    word_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i in range(1000): # size of test set is 1000\n",
    "        char_count=0\n",
    "        c0,c1,c2,c3,c4,c5,c6 = get_char_count(oh_encoding(pred_list[i]))\n",
    "        d0,d1,d2,d3,d4,d5,d6 = get_char_count(oh_encoding(answer_list[i]))\n",
    "        c = '%s%s%s%s%s%s%s' % (c0, c1, c2, c3, c4, c5, c6)\n",
    "        d = '%s%s%s%s%s%s%s' % (d0, d1, d2, d3, d4, d5, d6)\n",
    "        char_count += (c0==d0)+(c1==d1)+(c2==d2)+(c3==d3)+(c4==d4)+(c5==d5)+(c6==d6)\n",
    "        char_correct += char_count\n",
    "        if(bool(str(answer_list[i]) in str(c))):\n",
    "            word_correct+=1\n",
    "        total += 1\n",
    "    if max_accuracy < (100*(char_correct/(total*7))+100*word_correct/total):\n",
    "        max_accuracy = (100*(char_correct/(total*7))+100*word_correct/total)\n",
    "        best_epoch = epoch\n",
    "    print(\"------------------------------------\")\n",
    "    print(\"current...\")\n",
    "    print(epoch, end=':')\n",
    "    print(100*(char_correct/(total*7))+100*word_correct/total)\n",
    "    print(\"best...\")\n",
    "    print(best_epoch, end=\":\")\n",
    "    print(max_accuracy)\n",
    "    epoch += 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231\n"
     ]
    }
   ],
   "source": [
    "print(best_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---char correct---\n",
      "88.2 %\n",
      "---word correct---\n",
      "77.9 %\n"
     ]
    }
   ],
   "source": [
    "'''Test'''\n",
    "\n",
    "def get_char_count(arg1):\n",
    "    c0 = ALL_CHAR_SET[np.argmax(arg1[0:ALL_CHAR_SET_LEN])]\n",
    "    c1 = ALL_CHAR_SET[np.argmax(arg1[ALL_CHAR_SET_LEN:ALL_CHAR_SET_LEN*2])]\n",
    "    c2 = ALL_CHAR_SET[np.argmax(arg1[ALL_CHAR_SET_LEN*2:ALL_CHAR_SET_LEN*3])]\n",
    "    c3 = ALL_CHAR_SET[np.argmax(arg1[ALL_CHAR_SET_LEN*3:ALL_CHAR_SET_LEN*4])]\n",
    "    c4 = ALL_CHAR_SET[np.argmax(arg1[ALL_CHAR_SET_LEN*4:ALL_CHAR_SET_LEN*5])]\n",
    "    c5 = ALL_CHAR_SET[np.argmax(arg1[ALL_CHAR_SET_LEN*5:ALL_CHAR_SET_LEN*6])]\n",
    "    c6 = ALL_CHAR_SET[np.argmax(arg1[ALL_CHAR_SET_LEN*6:ALL_CHAR_SET_LEN*7])]\n",
    "    return c0, c1, c2,c3, c4, c5, c6 \n",
    "\n",
    "def oh_encoding(a):\n",
    "    label_oh = []\n",
    "    for i in range(7):\n",
    "        if i<len(a):\n",
    "            label_oh+=encode(a[i])\n",
    "        else:\n",
    "            label_oh+=encode('NONE')\n",
    "    return label_oh\n",
    "\n",
    "#best weight of Cap2TxT Network.\n",
    "model_path ='./ckpt/Cap2TxT_GoogLe_'+str(best_epoch)+'.pth'\n",
    "image_path = './Data/test/'\n",
    "\n",
    "pred_list =[]\n",
    "\n",
    "class_num = len(alphabet) + 1\n",
    "\n",
    "model = Cap2TxT(hidden_size,class_num)\n",
    "model = model.cuda()\n",
    "\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "converter = utils.strLabelConverter(alphabet)\n",
    "transformer=dataset.resizeNormalize((160,64))\n",
    "for i in range(1000):\n",
    "    image = Image.open(image_path+str(i)+'.png').convert('L')\n",
    "    image = transformer(image)\n",
    "    if torch.cuda.is_available():\n",
    "        image = image.cuda()\n",
    "    image = image.view(1, *image.size())\n",
    "    image = Variable(image)\n",
    "    preds = model(image)\n",
    "\n",
    "    _, preds = preds.max(2)\n",
    "    preds = preds.transpose(1, 0).contiguous().view(-1)\n",
    "    preds_size = Variable(torch.LongTensor([preds.size(0)]))\n",
    "    pred = converter.decode(preds.data, preds_size.data, raw=False)\n",
    "    pred_list.append(pred)\n",
    "\n",
    "answer='./Data/test.txt'\n",
    "answer_list=list()\n",
    "with open (answer) as f:\n",
    "    for line in f:\n",
    "        answer_list.append(line.rstrip('\\n'))\n",
    "\n",
    "char_correct = 0\n",
    "word_correct = 0\n",
    "total = 0\n",
    "\n",
    "for i in range(1000): # size of test set is 1000\n",
    "    char_count=0\n",
    "    c0,c1,c2,c3,c4,c5,c6 = get_char_count(oh_encoding(pred_list[i]))\n",
    "    d0,d1,d2,d3,d4,d5,d6 = get_char_count(oh_encoding(answer_list[i]))\n",
    "    c = '%s%s%s%s%s%s%s' % (c0, c1, c2, c3, c4, c5, c6)\n",
    "    d = '%s%s%s%s%s%s%s' % (d0, d1, d2, d3, d4, d5, d6)\n",
    "    char_count += (c0==d0)+(c1==d1)+(c2==d2)+(c3==d3)+(c4==d4)+(c5==d5)+(c6==d6)\n",
    "    char_correct += char_count\n",
    "    if(bool(str(answer_list[i]) in str(c))):\n",
    "        word_correct+=1\n",
    "    total += 1\n",
    "\n",
    "print('---char correct---')\n",
    "print(100*(char_correct/(total*7)), end=' ')\n",
    "print('%')\n",
    "print('---word correct---')\n",
    "print(100*word_correct/total, end=' ')\n",
    "print('%')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
