{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D0zuYQzwiO8Z"
   },
   "source": [
    "# M2608.001300 Machine Learning<br> Assignment #5 Final Projects (Pytorch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ri0oOICuC64e"
   },
   "source": [
    "Copyright (C) Data Science & AI Laboratory, Seoul National University. This material is for educational uses only. Some contents are based on the material provided by other paper/book authors and may be copyrighted by them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CJfG1l3RC_c3"
   },
   "source": [
    "**For understanding of this work, please carefully look at given PPT file.**\n",
    "\n",
    "Note: certain details are missing or ambiguous on purpose, in order to test your knowledge on the related materials. However, if you really feel that something essential is missing and cannot proceed to the next step, then contact the teaching staff with clear description of your problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "M9yv4oGGDbmJ",
    "outputId": "76b24c10-0f36-407e-9bb7-2c9ce3b5edff"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "import random\n",
    "import yaml\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from torch.nn import CTCLoss\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import utils\n",
    "import params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "acvGcUAaEkxe"
   },
   "source": [
    "Load datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "UcPk4u8qGZHB",
    "outputId": "5b4bfcbc-c731-4704-ae17-649e9f6d16ac"
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "alphabet='0123456789abcdefghijklmnopqrstuvwxyz'\n",
    "NUMBER = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "ALPHABET = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "NONE = ['NONE'] # label for empty space\n",
    "ALL_CHAR_SET = NUMBER + ALPHABET + NONE\n",
    "ALL_CHAR_SET_LEN = len(ALL_CHAR_SET)\n",
    "MAX_CAPTCHA = 7\n",
    "\n",
    "def encode(a):\n",
    "    onehot = [0]*ALL_CHAR_SET_LEN\n",
    "    idx = ALL_CHAR_SET.index(a)\n",
    "    onehot[idx] += 1\n",
    "    return onehot\n",
    "\n",
    "class Mydataset(Dataset):\n",
    "    def __init__(self, img_path, label_path, is_train=True, transform=None):\n",
    "        self.path = img_path\n",
    "        self.label_path = label_path\n",
    "        if is_train: \n",
    "            self.img = os.listdir(self.path)[:10000]\n",
    "            self.labels = open(self.label_path, 'r').read().split('\\n')[:-1][:10000]\n",
    "        else: \n",
    "            self.img = os.listdir(self.path)[:1000]\n",
    "            self.labels = open(self.label_path, 'r').read().split('\\n')[:-1][:1000]\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.max_length = MAX_CAPTCHA\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img[idx]\n",
    "        img = Image.open(f'{self.path}/{self.img[idx]}')\n",
    "        img = img.convert('L')\n",
    "        label = self.labels[idx]\n",
    "        label_oh = []\n",
    "        \n",
    "        for i in range(self.max_length):\n",
    "            if i < len(label):\n",
    "                label_oh += encode(label[i])\n",
    "            else:\n",
    "                #label_oh += [0]*ALL_CHAR_SET_LEN\n",
    "                label_oh += encode('NONE')\n",
    "            \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, np.array(label_oh), label\n",
    "    def __len__(self):\n",
    "        return len(self.img)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize([160, 60]),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "EFtlQyubGJZb",
    "outputId": "4697c0a5-d24a-4e05-f226-14021b625f5e"
   },
   "outputs": [],
   "source": [
    "gPath = './'\n",
    "train_ds = Mydataset(gPath+'Data/train/', gPath+'Data/train.txt',transform=transform)\n",
    "test_ds = Mydataset(gPath+'Data/test/', gPath+'Data/test.txt',False, transform)\n",
    "train_dl = DataLoader(train_ds, batch_size=64, num_workers=4)\n",
    "test_dl = DataLoader(test_ds, batch_size=1, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare dataset for me\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python misc.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python misc_2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python misc_3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create_dataset.py:14: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\r\n",
      "  imageBuf = np.fromstring(imageBin, dtype=np.uint8)\r\n"
     ]
    }
   ],
   "source": [
    "!python create_dataset.py --out Data/train_prepared --folder Data/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ka5SgX6VIWcG"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tJaHW3wSENjY"
   },
   "source": [
    "Problem 1: Design LSTM model for captcha image recognition. (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "rHEe3XmBFQHq",
    "outputId": "5b4bfcbc-c731-4704-ae17-649e9f6d16ac"
   },
   "outputs": [],
   "source": [
    "class ONE_LAYER_LSTM(nn.Module):\n",
    "    def __init__(self, dim_in, dim_hidden, dim_out)\n",
    "        super(ONE_LAYER_LSTM,self).__init__()\n",
    "        self.lstm = nn.LSTM(dim_in, dim_hidden, bidirectional=True)\n",
    "        self.fc_out = nn.Linear(2*dim_hidden, dim_out)\n",
    "    def forward(self, features)\n",
    "        tmp, _ = self.lstm(features)\n",
    "        T,b,h = tmp.size()\n",
    "        tmp = tmp.view(T*b,h)\n",
    "        output = self.fc_out(tmp)\n",
    "        output = output.view(T,b,-1)\n",
    "        return output\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, cnn_dim, hidden_size, classnum, num_layers=2):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstmnet = nn.Sequential(ONE_LAYER_LSTM(cnn_dim, hidden_size, hidden_size),\n",
    "                                    ONE_LAYER_LSTM(hidden_size,hidden_size, classnum))\n",
    "        \n",
    "    def forward(self, features):\n",
    "        output = self.lstmnet(features)\n",
    "        output = F.log_softmax(output,dim=2)\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TM2vL2PTFeEt"
   },
   "source": [
    "Problem 2: \n",
    "\n",
    "*   1.Connect CNN model to the designed LSTM model.\n",
    "*   2.Replace ResNet to your own CNN model from Assignment3.\n",
    "\n",
    "\n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# candidate 1\n",
    "'''my betternet from AS3'''\n",
    "\n",
    "class Inception(nn.Module):\n",
    "    def __init__(self, in_planes, n1x1, n3x3red, n3x3, n5x5red, n5x5, pool_planes):\n",
    "        super(Inception, self).__init__()\n",
    "        # 1x1 conv branch\n",
    "        self.b1 = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, n1x1, kernel_size=1),\n",
    "            nn.BatchNorm2d(n1x1),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        self.b2 = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, n3x3red, kernel_size=1),\n",
    "            nn.BatchNorm2d(n3x3red),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(n3x3red, n3x3, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n3x3),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        self.b3 = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, n5x5red, kernel_size=1),\n",
    "            nn.BatchNorm2d(n5x5red),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(n5x5red, n5x5, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(n5x5),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(n5x5, n5x5, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(n5x5),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        self.b4 = nn.Sequential(\n",
    "            nn.MaxPool2d(3, stride=1, padding=1),\n",
    "            nn.Conv2d(in_planes, pool_planes, kernel_size=1),\n",
    "            nn.BatchNorm2d(pool_planes),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        y1 = self.b1(x)\n",
    "        y2 = self.b2(x)\n",
    "        y3 = self.b3(x)\n",
    "        y4 = self.b4(x)\n",
    "        return torch.cat([y1,y2,y3,y4], 1)\n",
    "    \n",
    "class BetterNet_1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BetterNet_1, self).__init__()        \n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1,out_channels=64,kernel_size=7,stride=1,padding=3),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(3,2,1)\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64,out_channels=64,kernel_size=1,stride=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(in_channels=64,out_channels=192,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(3,2,1)\n",
    "        )\n",
    "        self.incep_block1 = nn.Sequential(\n",
    "            Inception(192,64,96,128,16,32,32),\n",
    "            Inception(256,128,128,192,32,96,64),\n",
    "            nn.MaxPool2d(3,2,1)\n",
    "        )        \n",
    "        self.incep_block2 = nn.Sequential(\n",
    "            Inception(480,192,96,208,16,48,64),\n",
    "            Inception(512,160,112,224,24,64,64),\n",
    "            Inception(512,128,128,256,24,64,64),\n",
    "            Inception(512,112,144,288,32,64,64),\n",
    "            Inception(528,256,160,320,32,128,128),\n",
    "            nn.MaxPool2d(3,2,1)\n",
    "        )        \n",
    "        self.incep_block3 = nn.Sequential(\n",
    "            Inception(832,256,160,320,32,128,128),\n",
    "            Inception(832,384,192,384,48,128,128),\n",
    "            nn.AvgPool2d(kernel_size=4,stride=1,padding=0)\n",
    "        )        \n",
    "        self.fc_block = nn.Sequential(\n",
    "            nn.Linear(1024,512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512,ALL_CHAR_SET_LEN*MAX_CAPTCHA)\n",
    "           # nn.ReLU(True),\n",
    "           # nn.Linear(64,10)\n",
    "        )        \n",
    "    def forward(self, x):\n",
    "        x=self.block1(x)\n",
    "        x=self.block2(x)\n",
    "        x=self.incep_block1(x)\n",
    "        x=self.incep_block2(x)\n",
    "        x=self.incep_block3(x)\n",
    "        #print('cnn 5:',end='')\n",
    "        #print(x.shape)\n",
    "        #x = x.view(-1,1024)\n",
    "        #x=self.fc_block(x)\n",
    "        out=x\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# candidate 2\n",
    "'''my betternet from AS3'''\n",
    "class BetterNet_2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BetterNet_2, self).__init__()\n",
    "        net=nn.Sequential()\n",
    "        net.add_module()\n",
    "        net.add_module()\n",
    "        net.add_module()\n",
    "        net.add_module()\n",
    "        net.add_module()\n",
    "        net.add_module()\n",
    "        net.add_module()\n",
    "        net.add_module()\n",
    "        net.add_module()\n",
    "        net.add_module()\n",
    "        net.add_module()\n",
    "        net.add_module()\n",
    "        net.add_module()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OwgpQ1aiFq2a"
   },
   "outputs": [],
   "source": [
    "# my CNN-RNN fusioned model, Cap2TxT Network\n",
    "\n",
    "class Cap2TxT(nn.Module):\n",
    "    def __init__(self, hidden_size, vocab_size, num_layers=2):\n",
    "        super(Cap2TxT, self).__init__()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "crnn = CRNN(hidden_size,vocab_size,1)\n",
    "crnn = crnn.to(device)\n",
    "\n",
    "loss_func = nn.MultiLabelSoftMarginLoss()\n",
    "crnn_optim = torch.optim.Adam(crnn.parameters(), lr=0.005)\n",
    "\n",
    "\n",
    "\n",
    "#loss_func = nn.MultiLabelSoftMarginLoss()\n",
    "#cnn_optim = torch.optim.Adam(betternet.parameters(), lr=0.001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F0uCexwRHsNz"
   },
   "source": [
    "Problem3: Find hyper-parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ibfVzKZeH1yC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 100 loss: 0.6958372592926025\n",
      "epoch: 2 step: 100 loss: 0.6955204010009766\n",
      "epoch: 3 step: 100 loss: 0.6954832673072815\n",
      "epoch: 4 step: 100 loss: 0.6954647302627563\n",
      "epoch: 5 step: 100 loss: 0.6954512596130371\n",
      "epoch: 6 step: 100 loss: 0.6954383850097656\n",
      "epoch: 7 step: 100 loss: 0.6954322457313538\n",
      "epoch: 8 step: 100 loss: 0.6954275369644165\n",
      "epoch: 9 step: 100 loss: 0.6954238414764404\n",
      "epoch: 10 step: 100 loss: 0.6954208016395569\n",
      "epoch: 11 step: 100 loss: 0.695418119430542\n",
      "epoch: 12 step: 100 loss: 0.695415735244751\n",
      "epoch: 13 step: 100 loss: 0.6954135894775391\n",
      "epoch: 14 step: 100 loss: 0.6954115629196167\n",
      "epoch: 15 step: 100 loss: 0.6954097747802734\n",
      "epoch: 16 step: 100 loss: 0.6954081058502197\n",
      "epoch: 17 step: 100 loss: 0.6954065561294556\n",
      "epoch: 18 step: 100 loss: 0.6954052448272705\n",
      "epoch: 19 step: 100 loss: 0.695404052734375\n",
      "epoch: 20 step: 100 loss: 0.6954030990600586\n",
      "Finished Training\n",
      "Saved Model\n"
     ]
    }
   ],
   "source": [
    "\"\"\"TRAINING\"\"\"\n",
    "\n",
    "PATH = './Cap2TxT.pth'\n",
    "print_interval = 100\n",
    "max_epoch = 20\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    for step, i in enumerate(train_dl):\n",
    "        img, label_oh, label = i\n",
    "        img = Variable(img).cuda()\n",
    "        label_oh = Variable(label_oh.float()).cuda()\n",
    "        batch_size, _ = label_oh.shape\n",
    "        \n",
    "        #pred, feature = betternet(img)\n",
    "        \n",
    "        \n",
    "        pred = crnn(img)\n",
    "        \n",
    "        #pred_resized = pred.reshape([batch_size,1,-1])\n",
    "        #pred_resized = pred_resized.squeeze(1)\n",
    "        \n",
    "        \n",
    "        loss = loss_func(pred, label_oh)\n",
    "        #cnn_optim.zero_grad()\n",
    "        crnn_optim.zero_grad()\n",
    "        loss.backward()\n",
    "        crnn_optim.step()\n",
    "        #cnn_optim.step() #TODO\n",
    "        \n",
    "##############################################################################\n",
    "#                          IMPLEMENT YOUR CODE                               #\n",
    "##############################################################################\n",
    "\n",
    "##############################################################################\n",
    "#                          END OF YOUR CODE                                  #\n",
    "##############################################################################\n",
    "        if (step+1)%print_interval == 0:\n",
    "            torch.save(crnn.state_dict(),PATH)\n",
    "            print('epoch:', epoch+1, 'step:', step+1, 'loss:', loss.item())\n",
    "\n",
    "print('Finished Training')\n",
    "torch.save(crnn.state_dict(),PATH)\n",
    "print('Saved Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e_uKOpe8IGJk"
   },
   "outputs": [],
   "source": [
    "'''Test'''\n",
    "\n",
    "def get_char_count(arg1):\n",
    "    c0 = ALL_CHAR_SET[np.argmax(arg1[0:ALL_CHAR_SET_LEN])]\n",
    "    c1 = ALL_CHAR_SET[np.argmax(arg1[ALL_CHAR_SET_LEN:ALL_CHAR_SET_LEN*2])]\n",
    "    c2 = ALL_CHAR_SET[np.argmax(arg1[ALL_CHAR_SET_LEN*2:ALL_CHAR_SET_LEN*3])]\n",
    "    c3 = ALL_CHAR_SET[np.argmax(arg1[ALL_CHAR_SET_LEN*3:ALL_CHAR_SET_LEN*4])]\n",
    "    c4 = ALL_CHAR_SET[np.argmax(arg1[ALL_CHAR_SET_LEN*4:ALL_CHAR_SET_LEN*5])]\n",
    "    c5 = ALL_CHAR_SET[np.argmax(arg1[ALL_CHAR_SET_LEN*5:ALL_CHAR_SET_LEN*6])]\n",
    "    c6 = ALL_CHAR_SET[np.argmax(arg1[ALL_CHAR_SET_LEN*6:ALL_CHAR_SET_LEN*7])]\n",
    "    return c0, c1, c2,c3, c4, c5, c6 \n",
    "\n",
    "def oh_encoding(a):\n",
    "    label_oh = []\n",
    "    for i in range(7):\n",
    "        if i<len(a):\n",
    "            label_oh+=encode(a[i])\n",
    "        else:\n",
    "            label_oh+=encode('NONE')\n",
    "    return label_oh\n",
    "\n",
    "\n",
    "#model_path = './ckpt/Cap2TxT2_155.pth'\n",
    "model_path = './ckpt/netCRNN_80_266.pth'\n",
    "image_path = './Data/test/'\n",
    "\n",
    "pred_list =[]\n",
    "\n",
    "nclass = len(params.alphabet) + 1\n",
    "model = CRNN(params.imgH, params.nc, nclass, params.nh)\n",
    "model = model.cuda()\n",
    "\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "converter = utils.strLabelConverter(alphabet)\n",
    "\n",
    "#transformer = dataset.resizeNormalize((160, 64))\n",
    "\n",
    "for i in range(1000):\n",
    "    image = Image.open(image_path+str(i)+'.png').convert('L')\n",
    "    image = transformer(image)\n",
    "    if torch.cuda.is_available():\n",
    "        image = image.cuda()\n",
    "    image = image.view(1, *image.size())\n",
    "    image = Variable(image)\n",
    "    preds = model(image)\n",
    "\n",
    "    _, preds = preds.max(2)\n",
    "    preds = preds.transpose(1, 0).contiguous().view(-1)\n",
    "    preds_size = Variable(torch.LongTensor([preds.size(0)]))\n",
    "    pred = converter.decode(preds.data, preds_size.data, raw=False)\n",
    "    pred_list.append(pred)\n",
    "\n",
    "gt='./Data/test.txt'\n",
    "lineList=list()\n",
    "with open (gt) as f:\n",
    "    for line in f:\n",
    "        lineList.append(line.rstrip('\\n'))\n",
    "\n",
    "char_correct = 0\n",
    "word_correct = 0\n",
    "total = 0\n",
    "\n",
    "for i in range(1000): # size of test set is 1000\n",
    "    char_count=0\n",
    "    c0,c1,c2,c3,c4,c5,c6 = get_char_count(oh_encoding(pred_list[i]))\n",
    "    d0,d1,d2,d3,d4,d5,d6 = get_char_count(oh_encoding(lineList[i]))\n",
    "    c = '%s%s%s%s%s%s%s' % (c0, c1, c2, c3, c4, c5, c6)\n",
    "    d = '%s%s%s%s%s%s%s' % (d0, d1, d2, d3, d4, d5, d6)\n",
    "    char_count += (c0==d0)+(c1==d1)+(c2==d2)+(c3==d3)+(c4==d4)+(c5==d5)+(c6==d6)\n",
    "    char_correct += char_count\n",
    "    if(bool(str(lineList[i]) in str(c))):\n",
    "        word_correct+=1\n",
    "    total += 1\n",
    "\n",
    "print('---char correct---')\n",
    "print(100*(char_correct/(total*7)), end=' ')\n",
    "print('%')\n",
    "print('---word correct---')\n",
    "print(100*word_correct/total, end=' ')\n",
    "print('%')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
